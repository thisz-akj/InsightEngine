{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743e5467-23d4-483a-83ed-861ea325444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EasyOCR reader globally, use CPU by setting gpu=True to avoid CUDA issues\n",
    "import easyocr  # For Optical Character Recognition (OCR)\n",
    "import requests  # To fetch images from URLs\n",
    "from PIL import Image  # For handling image processing\n",
    "from io import BytesIO  # To convert the response content into bytes\n",
    "import numpy as np  # For handling image arrays\n",
    "import cv2  # For image processing (e.g., converting to grayscale)\n",
    "import concurrent.futures  # For multi-threaded processing\n",
    "import gc  # To manually manage memory and run garbage collection\n",
    "import time  # To add delays between batch processing\n",
    "import pandas as pd  # To work with DataFrames\n",
    "\n",
    "# Initialize EasyOCR reader globally, use GPU by setting gpu=True \n",
    "reader = easyocr.Reader(['en'], gpu=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07790f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "# Initialize EasyOCR reader globally, use CPU by setting gpu=False to avoid CUDA issues\n",
    "reader = easyocr.Reader(['en'], gpu=True)  # Use CPU to save GPU memory for large datasets\n",
    "print(\"check1\")\n",
    "\n",
    "def preprocess_image(image):\n",
    "    max_size = (500,500)  # Resize to a smaller size to reduce memory usage\n",
    "    image.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Convert the image to numpy array and grayscale\n",
    "    image_np = np.array(image)\n",
    "    gray_image = cv2.cvtColor(image_np, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    return gray_image  # Return the grayscale image\n",
    "\n",
    "def extract_text(image_url):\n",
    "    try:\n",
    "        # Fetch and open image from URL\n",
    "        response = requests.get(image_url)\n",
    "        response.raise_for_status()  # Check if request was successful\n",
    "        image = Image.open(BytesIO(response.content))\n",
    "        image_np = preprocess_image(image)  # Preprocess image\n",
    "        \n",
    "        # Extract text using EasyOCR\n",
    "        result = reader.readtext(image_np)\n",
    "        text = ' '.join([res[1] for res in result])\n",
    "        return text\n",
    "    except requests.RequestException as e:\n",
    "        return f\"Request error: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"Processing error: {e}\"\n",
    "\n",
    "def process_images_in_batches(image_urls, batch_size=1000):\n",
    "    num_threads = 2  # Reduce the number of threads to avoid memory overload\n",
    "    total_images = len(image_urls)\n",
    "    print(f\"Starting to process {total_images} images in batches of {batch_size}...\")\n",
    "    \n",
    "    for i in range(0, total_images, batch_size):\n",
    "        batch_urls = image_urls[i:i + batch_size]\n",
    "        print(f\"Processing batch {i // batch_size + 1} with {len(batch_urls)} images...\")\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "            results = list(executor.map(extract_text, batch_urls))\n",
    "        \n",
    "        # Write results incrementally (you can modify this to save to a file or DB)\n",
    "        df.loc[i:i + len(batch_urls) - 1, 'description'] = results\n",
    "        \n",
    "        # Clear memory\n",
    "        del results\n",
    "        gc.collect()  # Call garbage collector to free up memory\n",
    "        \n",
    "        print(f\"Batch {i // batch_size + 1} completed.\")\n",
    "        time.sleep(2)  # Small sleep to reduce system load\n",
    "\n",
    "    print(\"Completed processing all images.\")\n",
    "\n",
    "# Assuming df is your DataFrame and 'image_link' is the column with URLs\n",
    "image_urls = df['image_link'].tolist()\n",
    "process_images_in_batches(image_urls)\n",
    "\n",
    "# Save the DataFrame after all batches are processed\n",
    "df.to_csv('image_descriptions_test.csv', index=False)\n",
    "\n",
    "# Print a success message after completion\n",
    "print(\"All images processed, and descriptions saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
